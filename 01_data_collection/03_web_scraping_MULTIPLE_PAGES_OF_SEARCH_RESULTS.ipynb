{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9611e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4, re, time, random\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae0eefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.redfin.com/city/11961/CA/Menlo-Park/filter/property-type=house,include=sold-6mo',\n",
       " 'https://www.redfin.com/city/14325/CA/Palo-Alto/filter/property-type=house,include=sold-6mo',\n",
       " 'https://www.redfin.com/city/12739/CA/Mountain-View/filter/property-type=house,include=sold-6mo',\n",
       " 'https://www.redfin.com/city/19457/CA/Sunnyvale/filter/property-type=house,include=sold-6mo',\n",
       " 'https://www.redfin.com/city/4561/CA/Cupertino/filter/property-type=house,include=sold-6mo',\n",
       " 'https://www.redfin.com/city/17675/CA/Santa-Clara/filter/property-type=house,include=sold-6mo',\n",
       " 'https://www.redfin.com/city/11018/CA/Los-Altos/filter/property-type=house,include=sold-6mo']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since Redfin limits search query results to 9 pages (40 results per page)\n",
    "# Prepare URLs to perform queries on a city by city basis in order to capture desired data\n",
    "cities = ['11961/CA/Menlo-Park/'\n",
    "          ,'14325/CA/Palo-Alto/'\n",
    "          ,'12739/CA/Mountain-View/'\n",
    "          ,'19457/CA/Sunnyvale/'\n",
    "          ,'4561/CA/Cupertino/'\n",
    "          ,'17675/CA/Santa-Clara/'\n",
    "          ,'11018/CA/Los-Altos/']\n",
    "\n",
    "# Homes sold on Redfin within the last 6 months, by city\n",
    "query_urls = ['https://www.redfin.com/city/' + city + 'filter/property-type=house,include=sold-6mo' for city in cities]\n",
    "query_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742e20d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. All page results URLs for city #1 added\n",
      "Success. All page results URLs for city #2 added\n",
      "Success. All page results URLs for city #3 added\n",
      "Success. All page results URLs for city #4 added\n",
      "Success. All page results URLs for city #5 added\n",
      "Success. All page results URLs for city #6 added\n",
      "Success. All page results URLs for city #7 added\n",
      "Collected a total of 44 URLs\n"
     ]
    }
   ],
   "source": [
    "# Building upon query URLs generated above\n",
    "# Prepare additional URLs to include all pages results, for each city search query of interest\n",
    "user_agent = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}    \n",
    "    \n",
    "query_list = []\n",
    "city_total = 1\n",
    "\n",
    "for query_url in query_urls:\n",
    "    \n",
    "    time.sleep(3 + 3*random.random())\n",
    "    \n",
    "    response = requests.get(query_url, headers = user_agent)\n",
    "    status = response.status_code\n",
    "    \n",
    "    if status == 200:\n",
    "        page = bs(response.text)\n",
    "        \n",
    "        page_num = int(page.find('div', class_='viewingPage').find('span', class_='pageText').text.split(' ')[-1])\n",
    "        \n",
    "        for num in range(1, page_num + 1):\n",
    "            query_list.append(query_url + '/page-' + str(num))\n",
    "        \n",
    "        print(f'Success. All page results URLs for city #{city_total} added')\n",
    "        \n",
    "        city_total += 1\n",
    "\n",
    "    else:\n",
    "        print(f'WARNING. Response Code {status} on query #{city_total}')\n",
    "        \n",
    "# Checking len \n",
    "print(f'Collected a total of {len(query_list)} URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f2e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing URL #1 added\n",
      "Listing URL #2 added\n",
      "Listing URL #3 added\n",
      "Listing URL #4 added\n",
      "Listing URL #5 added\n",
      "Listing URL #6 added\n",
      "Listing URL #7 added\n",
      "Listing URL #8 added\n",
      "Listing URL #9 added\n",
      "Listing URL #10 added\n",
      "Listing URL #11 added\n",
      "Listing URL #12 added\n",
      "Listing URL #13 added\n",
      "Listing URL #14 added\n",
      "Listing URL #15 added\n",
      "Listing URL #16 added\n",
      "Listing URL #17 added\n",
      "Listing URL #18 added\n",
      "Listing URL #19 added\n",
      "Listing URL #20 added\n",
      "Listing URL #21 added\n",
      "Listing URL #22 added\n",
      "Listing URL #23 added\n",
      "Listing URL #24 added\n",
      "Listing URL #25 added\n",
      "Listing URL #26 added\n",
      "Listing URL #27 added\n",
      "Listing URL #28 added\n",
      "Listing URL #29 added\n",
      "Listing URL #30 added\n",
      "Listing URL #31 added\n",
      "Listing URL #32 added\n",
      "Listing URL #33 added\n",
      "Listing URL #34 added\n",
      "Listing URL #35 added\n",
      "Listing URL #36 added\n",
      "Listing URL #37 added\n",
      "Listing URL #38 added\n",
      "Listing URL #39 added\n",
      "Listing URL #40 added\n",
      "Listing URL #41 added\n",
      "Listing URL #42 added\n",
      "Listing URL #43 added\n",
      "Listing URL #44 added\n",
      "Listing URLs scraping complete!\n"
     ]
    }
   ],
   "source": [
    "# For each results page URL collected, scrape for listing URLs on each page for a total of 1500+\n",
    "url_no = 1\n",
    "listing_urls = []\n",
    "\n",
    "for each_url in query_list:\n",
    "    \n",
    "    time.sleep(3 + 3*random.random())\n",
    "        \n",
    "    response = requests.get(each_url, headers = user_agent)\n",
    "    status = response.status_code\n",
    "    \n",
    "    if status == 200:\n",
    "        page_results = bs(response.text)\n",
    "        \n",
    "        tags_of_interest = page_results.find_all('a', {'class': 'slider-item'})\n",
    "        \n",
    "        for obj in tags_of_interest:\n",
    "            listing_urls.append('https://www.redfin.com' + obj['href'])\n",
    "    \n",
    "        print(f'Listing URL #{url_no} added')\n",
    "        \n",
    "        url_no += 1\n",
    "        \n",
    "    else:\n",
    "        print(f'WARNING. Response Code {status} on Listing URL #{url_no}')\n",
    "              \n",
    "print('Listing URLs scraping complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32990e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listing_urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
